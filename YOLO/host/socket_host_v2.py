#!/usr/bin/env python3

"""
The code was modified from code generated by Gemini, Claude,
and ChatGPT, and has been reviewed and cleaned up by Claude

Author: Chung Wei
Date: 2025.9.8
"""

import socket
import pickle
import struct
import cv2
import numpy as np
import os
import time
import argparse
import logging
from typing import Optional, Tuple, List, Dict, Any

from utils.neuronpilot import neuronrt

HOST = '0.0.0.0'
PORT = 5001
SOCKET_TIMEOUT = 30.0
MAX_IMAGE_SIZE = 50 * 1024 * 1024  # 50MB

# COCO Dataset Class Names
COCO_CLASSES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
    'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
    'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',
    'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
    'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def receive_image(conn: socket.socket) -> Optional[Tuple[np.ndarray, dict]]:
    """
    Receive image data from client with error handling and timeout mechanism
    
    Args:
        conn: Socket connection object
        
    Returns:
        Tuple of (decoded_image, transform_info) or None if failed
    """
    try:
        conn.settimeout(SOCKET_TIMEOUT)
        
        # Receive 4 bytes indicating data size
        size_data = conn.recv(4)
        if len(size_data) != 4:
            logger.warning("Failed to receive complete size data")
            return None
            
        data_len = struct.unpack('>I', size_data)[0]
        
        # Validate data size
        if data_len > MAX_IMAGE_SIZE:
            logger.warning(f"Image size too large: {data_len} bytes")
            return None
            
        logger.debug(f"Expecting {data_len} bytes of image data")
        
        # Receive image data in chunks
        data = b''
        while len(data) < data_len:
            remaining = data_len - len(data)
            chunk_size = min(4096, remaining)
            packet = conn.recv(chunk_size)
            if not packet:
                logger.warning("Connection closed while receiving image data")
                break
            data += packet
            
        if len(data) != data_len:
            logger.warning(f"Incomplete image data: received {len(data)}, expected {data_len}")
            return None

        logger.info(f"Received raw data size: {len(data)} bytes")
        
        # Deserialize payload
        payload = pickle.loads(data)
        if not isinstance(payload, dict):
            logger.error("Received payload is not a dict")
            return None
        
        # Extract image bytes and transform info
        img_bytes = payload.get("image", None)
        transform_info = payload.get("transform_info", None)

        if img_bytes is None or transform_info is None:
            logger.error("Payload missing required keys (image or transform_info)")
            return None
    
        # Decode JPEG image
        img = cv2.imdecode(np.frombuffer(img_bytes, np.uint8), cv2.IMREAD_COLOR)
        if img is None:
            logger.warning("Failed to decode image from payload")
            return None
        
        # Validate image data
        if img.max() <= 1.0:
            logger.warning("Image values seem to be normalized (0-1), might need scaling")
        elif img.max() > 255:
            logger.warning("Image values exceed 255, might be in wrong format")
    
        logger.debug(f"Decoded resized image shape: {img.shape}, dtype: {img.dtype}")
        return img, transform_info
        
    except socket.timeout:
        logger.warning("Socket timeout while receiving image")
        return None
    except Exception as e:
        logger.error(f"Error receiving image: {e}")
        import traceback
        logger.error(f"Full traceback: {traceback.format_exc()}")
        return None

def send_result(conn: socket.socket, result_data: Dict[str, Any]) -> bool:
    """
    Send detection results to client
    
    Args:
        conn: Socket connection object
        result_data: Dictionary containing detection results
        
    Returns:
        True if successful, False otherwise
    """
    try:
        payload = pickle.dumps(result_data)
        conn.sendall(struct.pack('>I', len(payload)) + payload)
        logger.debug(f"Sent result: {len(payload)} bytes")
        return True
        
    except Exception as e:
        logger.error(f"Error sending result: {e}")
        return False

def preprocess_image(image: np.ndarray) -> np.ndarray:
    """
    Prepare input image for NeuroPilot YOLO model inference
    
    Args:
        image: Input image in BGR format
        
    Returns:
        Preprocessed image tensor ready for inference
    """
    input_data = image.astype(np.float32)
    
    # Convert BGR to RGB
    input_data = input_data[..., ::-1]
    
    # Normalize to [0, 1]
    input_data /= 255.0
    
    # Ensure contiguous memory layout
    input_data = np.ascontiguousarray(input_data)
    
    # Add batch dimension
    input_data = np.expand_dims(input_data, axis=0)
    
    print(f"Preprocessed input shape: {input_data.shape}, type: {input_data.dtype}")
    return input_data

def postprocess(preds: np.ndarray, transform_info: dict, conf_thres: float = 0.25, 
                iou_thres: float = 0.45, classes: Optional[List[int]] = None, 
                agnostic: bool = False, max_det: int = 300, nc: int = 80) -> List:
    """
    Post-process YOLO model outputs for NeuroPilot SDK
    
    Args:
        preds: Model predictions with shape (1, 8400, 84)
        transform_info: Image preprocessing transformation information
        conf_thres: Confidence threshold for filtering detections
        iou_thres: IoU threshold for Non-Maximum Suppression
        classes: Optional list of class indices to filter
        agnostic: Whether to use class-agnostic NMS
        max_det: Maximum number of detections to keep
        nc: Number of classes
        
    Returns:
        List of detection results for each image in batch
    """
    results = []
    
    for i, pred in enumerate(preds):
        # Calculate class confidence scores
        class_scores = np.max(pred[:, 5:5+nc], axis=1)
        class_ids = np.argmax(pred[:, 5:5+nc], axis=1)
        
        # Filter by confidence threshold
        conf_mask = class_scores > conf_thres
        filtered_pred = pred[conf_mask]
        filtered_scores = class_scores[conf_mask]
        filtered_class_ids = class_ids[conf_mask]
        
        print(f"Confidence threshold: {conf_thres}")
        print(f"Class confidence range: {np.min(class_scores)} - {np.max(class_scores)}")
        print(f"Boxes after confidence filtering: {filtered_pred.shape[0]}")
        
        if filtered_pred.shape[0] == 0:
            results.append(None)
            continue
            
        # Convert xywh to xyxy format
        boxes = filtered_pred[:, :4].copy()
        boxes = xywh2xyxy(boxes)
        
        # Convert normalized coordinates to absolute coordinates (model input size)
        input_h, input_w = transform_info['new_shape']
        boxes[:, [0, 2]] *= input_w  # x coordinates
        boxes[:, [1, 3]] *= input_h  # y coordinates
        
        # Remove letterbox padding
        pad_left, pad_top = transform_info['pad']
        boxes[:, [0, 2]] -= pad_left
        boxes[:, [1, 3]] -= pad_top
        
        # Scale back to original image size
        ratio_w, ratio_h = transform_info['ratio']
        boxes[:, [0, 2]] /= ratio_w
        boxes[:, [1, 3]] /= ratio_h
        
        # Clip coordinates to original image boundaries
        orig_h, orig_w = transform_info['original_shape']
        boxes[:, [0, 2]] = np.clip(boxes[:, [0, 2]], 0, orig_w)
        boxes[:, [1, 3]] = np.clip(boxes[:, [1, 3]], 0, orig_h)

        # Combine results: [x1, y1, x2, y2, conf, class_id]
        det = np.column_stack((boxes, filtered_scores, filtered_class_ids))
        
        # Apply Non-Maximum Suppression
        if det.shape[0] > 1:
            boxes_for_nms, scores = det[:, :4], det[:, 4]
            nms_indices = non_max_suppression(boxes_for_nms, scores, iou_thres)
            if isinstance(nms_indices, list):
                nms_indices = np.array(nms_indices)
            det = det[nms_indices[:max_det]]
        
        print(f"Boxes after NMS: {det.shape[0]}")
        results.append(det)
    return results

def xywh2xyxy(x: np.ndarray) -> np.ndarray:
    """
    Convert bounding box format from (center_x, center_y, width, height) to (x1, y1, x2, y2)
    
    Args:
        x: Bounding boxes in xywh format
        
    Returns:
        Bounding boxes in xyxy format
    """
    assert x.shape[-1] == 4, f"Input shape last dimension expected 4 but got {x.shape}"
    y = np.empty_like(x)
    xy = x[..., :2]  # center coordinates
    wh = x[..., 2:] / 2  # half width and height
    y[..., :2] = xy - wh  # top-left corner
    y[..., 2:] = xy + wh  # bottom-right corner
    return y

def non_max_suppression(boxes: np.ndarray, scores: np.ndarray, iou_threshold: float) -> np.ndarray:
    """
    Perform Non-Maximum Suppression on detection results
    
    Args:
        boxes: Bounding boxes in xyxy format
        scores: Confidence scores for each box
        iou_threshold: IoU threshold for suppression
        
    Returns:
        Indices of boxes to keep after NMS
    """
    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]

    areas = (x2 - x1) * (y2 - y1)
    order = scores.argsort()[::-1]

    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        
        # Calculate intersection coordinates
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        
        # Calculate intersection area and IoU
        w = np.maximum(0.0, xx2 - xx1)
        h = np.maximum(0.0, yy2 - yy1)
        inter = w * h
        iou = inter / (areas[i] + areas[order[1:]] - inter)
        
        # Keep boxes with IoU below threshold
        inds = np.where(iou <= iou_threshold)[0]
        order = order[inds + 1]

    return np.array(keep)

def setup_directories():
    """Create necessary directories for model and binary files"""
    os.makedirs('./models', exist_ok=True)
    os.makedirs('./bin', exist_ok=True)

def initialize_model(model_path: str, device: str) -> Tuple[neuronrt.Interpreter, tuple]:
    """
    Initialize NeuroPilot interpreter and get model details
    
    Args:
        model_path: Path to TensorFlow Lite model file
        device: Target device for acceleration
        
    Returns:
        Tuple of (interpreter, input_shape)
    """
    logger.info(f"Loading model: {model_path}")
    interpreter = neuronrt.Interpreter(model_path=model_path, device=device)
    interpreter.allocate_tensors()
    
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Determine input shape
    if len(input_details) > 0 and len(input_details[0]['shape']) >= 3:
        input_shape = tuple(input_details[0]['shape'][1:3])  # [batch, height, width, channels]
        if input_shape[0] == 0 or input_shape[1] == 0:
            input_shape = (640, 640)
    else:
        input_shape = (640, 640)
    
    logger.info(f"Model input shape: {input_shape}")
    return interpreter, input_shape

def process_detection_results(results: List, start_time: float) -> Dict[str, Any]:
    """
    Convert model predictions to structured detection results
    
    Args:
        results: Post-processed detection results
        start_time: Processing start timestamp
        
    Returns:
        Dictionary containing formatted detection results
    """
    boxes = []
    
    for det in results:
        if det is None:
            continue
        
        # Convert each detection to dictionary format
        for i in range(det.shape[0]):
            x1, y1, x2, y2, conf, cls_id = det[i]
            cls_id = int(cls_id) + 1  # Adjust class ID indexing

            boxes.append({
                "cls": int(cls_id),
                "conf": float(conf),
                "xyxy": [float(x1), float(y1), float(x2), float(y2)]
            })

    return {
        "boxes": boxes,
        "processing_time": time.time() - start_time
    }

def run_server(interpreter: neuronrt.Interpreter, input_details: List, output_details: List):
    """
    Main server loop for handling client connections and processing requests
    
    Args:
        interpreter: NeuroPilot interpreter instance
        input_details: Model input tensor details
        output_details: Model output tensor details
    """
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        s.bind((HOST, PORT))
        s.listen(1)
        logger.info(f"Server listening on {HOST}:{PORT}")
        
        while True:  # Handle multiple connections
            try:
                conn, addr = s.accept()
                logger.info(f"Connected by {addr}")
                
                with conn:
                    while True:  # Handle multiple requests per connection
                        try:
                            start_time = time.time()
                            
                            # Receive and decode image
                            result = receive_image(conn)
                            if result is None:
                                logger.info("No image received. Closing connection.")
                                break
                            
                            img, transform_info = result

                            # Preprocess image
                            input_data = preprocess_image(img)

                            # Ensure correct data type
                            input_dtype = input_details[0]['dtype']
                            if input_data.dtype != input_dtype:
                                input_data = input_data.astype(input_dtype)

                            # Run inference
                            interpreter.set_tensor(input_details[0]['index'], input_data)
                            interpreter.invoke()
                            output_data = interpreter.get_tensor(output_details[0]['index'])

                            # Post-process results
                            output_data = output_data.transpose(0, 2, 1)
                            results = postprocess(output_data, transform_info, 
                                                conf_thres=0.25, 
                                                iou_thres=0.45)

                            # Format detection results
                            result_data = process_detection_results(results, start_time)
                            
                            # Send results back to client
                            if not send_result(conn, result_data):
                                break
                                
                            logger.info(f"Processing time: {result_data['processing_time']:.3f}s, "
                                      f"Detected objects: {len(result_data['boxes'])}")

                        except Exception as e:
                            logger.error(f"Error processing request: {e}")
                            break
                            
            except KeyboardInterrupt:
                logger.info("Server stopped by user")
                break
            except Exception as e:
                logger.error(f"Server error: {e}")
                continue

def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description="YOLO Inference Server with NeuroPilot SDK")
    parser.add_argument("-m", "--tflite_model", type=str, required=True, 
                       help="Path to TensorFlow Lite model file")
    parser.add_argument("-d", "--device", type=str, default='mdla3.0', 
                       choices=['mdla3.0', 'mdla2.0', 'vpu'], 
                       help="Device name for acceleration")
    args = parser.parse_args()

    # Validate model file
    if not os.path.exists(args.tflite_model):
        raise FileNotFoundError(f"Model file doesn't exist: {args.tflite_model}")
    
    # Setup environment
    setup_directories()
    logging.getLogger().setLevel(logging.DEBUG)

    # Initialize model
    interpreter, input_shape = initialize_model(args.tflite_model, args.device)
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # Start server
    logger.info("Starting YOLO inference server...")
    run_server(interpreter, input_details, output_details)

if __name__ == "__main__":
    main()